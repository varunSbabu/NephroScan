% ============================================================================
% NephroScan: An Explainable ML Framework for CKD Detection
% IEEE Conference Paper — 7 Pages, IEEEtran
% ============================================================================
\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{url}
\usepackage{float}
\usepackage{stfloats}
\usepackage{balance}

\graphicspath{{figures/}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

% ═══════════════════════════════════════════════════════════════════════════
%  TITLE & AUTHORS
% ═══════════════════════════════════════════════════════════════════════════
\title{NephroScan: An Explainable Machine Learning Framework for\\
Chronic Kidney Disease Detection with Clinical Validation}

\author{
\IEEEauthorblockN{Author One\IEEEauthorrefmark{1},
Author Two\IEEEauthorrefmark{2} and
Author Three\IEEEauthorrefmark{3}}
\IEEEauthorblockA{Department of Computer Science and Engineering\\
Institution Name, City, Country\\
\{author1, author2, author3\}@institution.edu}
}

\maketitle

% ═══════════════════════════════════════════════════════════════════════════
%  ABSTRACT
% ═══════════════════════════════════════════════════════════════════════════
\begin{abstract}
Chronic Kidney Disease (CKD) affects over 850~million people worldwide and
progresses asymptomatically until advanced stages, making early automated
detection critical. This paper presents \textbf{NephroScan}, an end-to-end
explainable machine learning framework addressing three persistent gaps in
CKD prediction: data leakage in cross-validation pipelines, limited clinical
alignment, and black-box model opacity. We evaluate nine classifiers on the
UCI CKD dataset ($n{=}400$) using strictly leakage-free 10-fold stratified
cross-validation wherein imputation and scaling are fitted exclusively on
training folds. A four-method consensus feature selection (LASSO, RFE, Mutual
Information, SHAP) identifies a compact 7-feature subset retaining 99.96\%
AUC. Bayesian hyperparameter optimisation via Optuna (100 trials) further
refines five models. Logistic Regression achieves AUC~$= 0.9997$; a 9-model
majority-vote ensemble attains 99.25\% accuracy, $F_1{=}0.994$, and
MCC~$= 0.984$. SHapley Additive exPlanations (SHAP) identify specific
gravity, haemoglobin, albumin, and serum creatinine as dominant biomarkers,
consistent with nephrology domain knowledge. Clinical validation against
KDIGO staging and decision-curve analysis confirms real-world applicability.
\end{abstract}

\begin{IEEEkeywords}
Chronic Kidney Disease, Machine Learning, Explainable AI, SHAP,
Clinical Decision Support, Feature Selection, Ensemble Learning
\end{IEEEkeywords}

% ═══════════════════════════════════════════════════════════════════════════
%  I. INTRODUCTION
% ═══════════════════════════════════════════════════════════════════════════
\section{Introduction}

Chronic Kidney Disease (CKD) is characterised by progressive, irreversible
decline in kidney function measured via the estimated glomerular filtration
rate (eGFR)~\cite{kdigo2024}. With a global prevalence exceeding 850~million,
CKD is projected to become the fifth-leading cause of death by
2040~\cite{bikbov2020}. Stages~1--3 are largely asymptomatic; most patients
receive diagnosis only after significant irreversible renal
damage~\cite{inker2021}. Early automated detection is therefore critical.

Machine learning (ML) has shown promise on the widely benchmarked UCI CKD
dataset~\cite{uci2015}. However, methodological gaps persist:
(i)~\emph{data leakage} through dataset-wide imputation before
cross-validation~\cite{kaufman2012}; (ii)~absence of KDIGO-aligned clinical
validation; (iii)~single-method feature selection bias; and (iv)~black-box
predictions hindering clinical trust.

\textbf{NephroScan} addresses all four gaps via: leakage-free CV pipelines,
four-method consensus feature selection, Bayesian hyperparameter tuning,
nine-model comparative evaluation, SHAP-based explainability, and KDIGO-stage
clinical validation. Fig.~\ref{fig:architecture} illustrates the complete
end-to-end system architecture.

% ═══════════════════════════════════════════════════════════════════════════
%  II. RELATED WORK
% ═══════════════════════════════════════════════════════════════════════════
\section{Related Work}

The UCI CKD dataset has served as a standard benchmark for over a decade.
Aljaaf~\textit{et al.}~\cite{aljaaf2019} applied Random Forest with 10-fold
CV achieving AUC~$= 0.997$. Qin~\textit{et al.}~\cite{qin2020} combined
XGBoost with SMOTE (AUC~$= 0.993$). Ogunleye and Wang~\cite{ogunleye2020}
integrated feature selection into XGBoost (AUC~$= 0.9986$).
Islam~\textit{et al.}~\cite{islam2022} proposed an RF+XGB+LR ensemble
(AUC~$= 0.9994$). Almansour~\textit{et al.}~\cite{almansour2023} employed
neural networks with KNN imputation (AUC~$= 0.999$).
Ali~\textit{et al.}~\cite{ali2023} embedded SHAP into gradient-boosted
trees for interpretable CKD risk stratification.
Zhu~\textit{et al.}~\cite{zhu2023} applied attention-based CNNs to
clinical tabular data (AUC~$= 0.991$).

Despite strong reported metrics, prior studies typically do not:
(i)~enforce verified leakage-free pipelines, (ii)~validate against KDIGO
eGFR staging, (iii)~report MCC --- an unbiased metric for imbalanced
data~\cite{chicco2020}, or (iv)~deliver cross-architecture SHAP analysis.
NephroScan addresses all four simultaneously with a reproducible pipeline.

% ═══════════════════════════════════════════════════════════════════════════
%  III. PROPOSED METHODOLOGY
% ═══════════════════════════════════════════════════════════════════════════
\section{Proposed Methodology}

Fig.~\ref{fig:architecture} presents the NephroScan system architecture
comprising seven tightly integrated phases: (1)~Data Acquisition and EDA,
(2)~Leakage-Free Preprocessing, (3)~Imputation Study, (4)~Consensus Feature
Selection, (5)~Model Training and Evaluation, (6)~Bayesian Hyperparameter
Optimisation, and (7)~SHAP Explainability with KDIGO Clinical Validation.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.88\textwidth]{nephroscan_architecture.png}
    \caption{NephroScan system architecture: end-to-end pipeline from UCI CKD
    data acquisition through leakage-free preprocessing, 9-classifier training
    with Bayesian HPO (Optuna), majority-vote ensemble prediction,
    SHAP explainability, and KDIGO clinical validation.}
    \label{fig:architecture}
\end{figure*}

\subsection{Dataset Description}

We use the UCI Machine Learning Repository CKD dataset~\cite{uci2015},
collected at Apollo Hospitals, India, containing 400~patient records with
24~features (11~numerical, 13~categorical) and binary target: CKD
($n{=}250$, 62.5\%) vs.~Not~CKD ($n{=}150$, 37.5\%). Table~\ref{tab:features}
lists key clinically relevant features with missingness rates. Sixteen of
24~features contain missing values (up to 38.25\% for \texttt{rbc}).

\begin{table}[!t]
\centering
\caption{Key Clinical Features of the UCI CKD Dataset}
\label{tab:features}
\setlength{\tabcolsep}{3.5pt}
\begin{tabular}{@{}llcc@{}}
\toprule
\textbf{Code} & \textbf{Clinical Name} & \textbf{Type} & \textbf{Miss.\%} \\
\midrule
sg   & Specific Gravity     & Num.  & 11.75 \\
al   & Albumin (urine)      & Num.  & 11.50 \\
hemo & Haemoglobin          & Num.  & 13.25 \\
sc   & Serum Creatinine     & Num.  &  4.25 \\
pcv  & Packed Cell Volume   & Num.  & 17.50 \\
rbc  & Red Blood Cells      & Cat.  & 38.25 \\
htn  & Hypertension         & Cat.  &  0.50 \\
dm   & Diabetes Mellitus    & Cat.  &  0.50 \\
bgr  & Blood Glucose Random & Num.  & 11.00 \\
bu   & Blood Urea           & Num.  &  4.75 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Data Preprocessing}

\subsubsection{Missing Data Imputation}
We compare four strategies within strictly leakage-free 10-fold CV pipelines
(imputer fitted per training fold): (A)~Mean/Mode, (B)~KNN ($k{=}5$),
(C)~MICE, and (D)~Missingness Indicator. Table~\ref{tab:imputation}
summarises AUC across four classifiers.

\begin{table}[!t]
\centering
\caption{Imputation Strategy Comparison (AUC, 10-Fold CV)}
\label{tab:imputation}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Strategy} & \textbf{RF} & \textbf{XGB} & \textbf{LR} & \textbf{GB} \\
\midrule
A: Mean/Mode       & 0.9995 & 0.9987 & 1.0000 & 0.9997 \\
B: KNN ($k{=}5$)   & 0.9995 & 0.9984 & 0.9997 & 0.9987 \\
C: MICE            & 0.9988 & 0.9981 & N/A$^*$ & N/A$^*$ \\
D: Miss.~Indicator & \textbf{1.000} & \textbf{1.000} & \textbf{1.000} & \textbf{1.000} \\
\bottomrule
\multicolumn{5}{l}{\footnotesize $^*$MICE diverged for LR and GB.}
\end{tabular}
\end{table}

Strategy~D achieves perfect AUC by encoding MNAR patterns correlated with
disease severity. All subsequent pipelines adopt \textbf{Strategy~B
(KNN, $k{=}5$)} for clinical interpretability, with Strategy~D as
sensitivity bound. Standard $z$-score scaling is applied within each fold.

\subsubsection{Leakage-Free Pipeline}
All preprocessing steps are encapsulated in an sklearn
\texttt{Pipeline}~\cite{scikit2011} fitted exclusively on training folds:
\[
\text{KNNImputer}(k{=}5) \rightarrow \text{StandardScaler} \rightarrow \text{Classifier}
\]
This eliminates test-fold data contamination, following leakage-avoidance
best practices~\cite{kaufman2012}.

\subsection{Four-Method Consensus Feature Selection}

To mitigate single-method selection bias, we aggregate rankings from four
complementary approaches: (1)~\textbf{LASSO} ($L_1$ logistic regression),
(2)~\textbf{RFE} (Recursive Feature Elimination via RF),
(3)~\textbf{Mutual Information}, and (4)~\textbf{SHAP} importance.
Features with $\geq 3/4$ votes are retained. Table~\ref{tab:feature_sel}
presents the 7-feature consensus subset achieving AUC~$= 0.9996$ (RF,
5-fold CV) --- retaining $>99.9\%$ discriminative power.

\begin{table}[!t]
\centering
\caption{Four-Method Consensus Feature Selection ($\geq 3/4$ Votes)}
\label{tab:feature_sel}
\setlength{\tabcolsep}{2.5pt}
\begin{tabular}{@{}clcccccr@{}}
\toprule
\textbf{Rk} & \textbf{Feat.} & \textbf{LASSO} & \textbf{RFE} & \textbf{MI} & \textbf{SHAP} & \textbf{V} & \textbf{C.Rk}\\
\midrule
1 & sg   & \checkmark & \checkmark & \checkmark & \checkmark & 4 & 1.50 \\
2 & hemo & \checkmark & \checkmark & \checkmark & \checkmark & 4 & 1.50 \\
3 & al   & \checkmark & \checkmark & \checkmark & \checkmark & 4 & 3.50 \\
4 & rbc  & \checkmark & \checkmark & \checkmark & \checkmark & 4 & 4.00 \\
5 & pcv  & \checkmark & \checkmark & \checkmark & \checkmark & 4 & 4.25 \\
6 & htn  & \checkmark & \checkmark & \checkmark & \checkmark & 4 & 5.50 \\
7 & dm   & \checkmark & \checkmark & ---        & \checkmark & 3 & 6.00 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Model Training and Hyperparameter Optimisation}

\subsubsection{Classifier Suite}
Nine classifiers spanning multiple paradigms are evaluated: Logistic
Regression~(LR), Support Vector Machine~(SVM, RBF kernel), Decision
Tree~(DT), Random Forest~(RF), Gradient Boosting~(GB),
XGBoost~\cite{chen2016}~(XGB), CatBoost~(CB), $k$-Nearest
Neighbours~(KNN, $k{=}5$), and Na{\"i}ve Bayes~(NB).

\subsubsection{Bayesian Hyperparameter Optimisation}
RF, XGB, CB, GB, and SVM undergo Bayesian optimisation via
Optuna~\cite{akiba2019} with 100~trials per model, TPE sampler, and 5-fold
CV AUC objective. Gradient Boosting benefits most ($\Delta$AUC~$= +0.00098$,
$\Delta F_1{=}+0.004$). Tuned RF: \texttt{n\_estimators}$= 500$,
\texttt{max\_depth}$= 13$, \texttt{bootstrap}$=$ False.

\subsubsection{Ensemble Strategy}
A 9-model majority-vote ensemble aggregates hard predictions across all
classifiers, providing robustness against individual model weaknesses.

% ═══════════════════════════════════════════════════════════════════════════
%  IV. EXPERIMENTAL RESULTS
% ═══════════════════════════════════════════════════════════════════════════
\section{Experimental Results}

\subsection{Cross-Validation Performance}

Table~\ref{tab:cv_results} presents 10-fold stratified CV results. All
metrics are computed on held-out folds (strictly out-of-fold, no leakage).

\begin{table*}[!tp]
\centering
\caption{10-Fold Stratified Cross-Validation Results (Mean $\pm$ Std) --- All Metrics Computed on Held-Out Folds}
\label{tab:cv_results}
\setlength{\tabcolsep}{4.5pt}
\begin{tabular}{@{}lcccccccc@{}}
\toprule
\textbf{Model} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall}
  & \textbf{Specificity} & \textbf{$F_1$} & \textbf{AUC} & \textbf{MCC}
  & \textbf{Cohen's $\kappa$}\\
\midrule
Logistic Regression
  & $.9925{\pm}.016$ & $1.000{\pm}.000$ & $.988{\pm}.026$ & $1.000{\pm}.000$
  & $.994{\pm}.013$ & $\mathbf{.9997{\pm}.001}$ & $.985{\pm}.032$ & $.984{\pm}.033$ \\
SVM (RBF)
  & $.9925{\pm}.016$ & $.996{\pm}.012$ & $.992{\pm}.016$ & $.993{\pm}.020$
  & $.994{\pm}.013$ & $.9992{\pm}.002$ & $.984{\pm}.034$ & $.984{\pm}.034$ \\
Random Forest
  & $.9900{\pm}.012$ & $.985{\pm}.019$ & $\mathbf{1.000{\pm}.000}$ & $.973{\pm}.033$
  & $.992{\pm}.010$ & $.9995{\pm}.001$ & $.979{\pm}.026$ & $.978{\pm}.027$ \\
Gradient Boosting
  & $.9925{\pm}.016$ & $.996{\pm}.012$ & $.992{\pm}.016$ & $.993{\pm}.020$
  & $.994{\pm}.013$ & $.9995{\pm}.002$ & $.984{\pm}.034$ & $.984{\pm}.034$ \\
XGBoost
  & $.9875{\pm}.017$ & $.992{\pm}.016$ & $.988{\pm}.018$ & $.987{\pm}.027$
  & $.990{\pm}.013$ & $.9989{\pm}.002$ & $.974{\pm}.035$ & $.973{\pm}.036$ \\
CatBoost
  & $.9875{\pm}.013$ & $.988{\pm}.018$ & $.992{\pm}.016$ & $.980{\pm}.031$
  & $.990{\pm}.010$ & $.9992{\pm}.002$ & $.974{\pm}.026$ & $.973{\pm}.027$ \\
KNN ($k{=}5$)
  & $.9700{\pm}.022$ & $1.000{\pm}.000$ & $.952{\pm}.035$ & $1.000{\pm}.000$
  & $.975{\pm}.019$ & $.9959{\pm}.008$ & $.940{\pm}.042$ & $.938{\pm}.045$ \\
Na{\"i}ve Bayes
  & $.9375{\pm}.039$ & $.979{\pm}.028$ & $.920{\pm}.047$ & $.967{\pm}.045$
  & $.948{\pm}.033$ & $.9828{\pm}.022$ & $.874{\pm}.079$ & $.870{\pm}.081$ \\
Decision Tree
  & $.9675{\pm}.023$ & $.980{\pm}.020$ & $.968{\pm}.030$ & $.967{\pm}.033$
  & $.974{\pm}.018$ & $.9673{\pm}.022$ & $.932{\pm}.047$ & $.931{\pm}.047$ \\
\midrule
\textbf{Ensemble (9-model)}
  & $\mathbf{.9925}$ & --- & --- & ---
  & $\mathbf{.9940}$ & $.9997^{\dagger}$ & $\mathbf{.984}$ & --- \\
\bottomrule
\multicolumn{9}{l}{\footnotesize $^{\dagger}$Best individual CV AUC (LR). Majority-vote ensemble AUC is approximated by best member.}
\end{tabular}
\end{table*}

Logistic Regression achieves the highest AUC (0.9997), demonstrating
near-linear separability after leakage-free preprocessing. Random Forest
attains perfect recall (1.000) --- critical for screening where false
negatives carry high clinical cost. Wilcoxon signed-rank tests
(Bonferroni-corrected, $\alpha{=}0.05$) confirm that LR, SVM, RF, GB,
XGB, and CatBoost are not statistically differentiated but collectively
outperform DT ($p{<}0.002$) and NB ($p{<}0.029$).

\subsection{Detection Accuracy and ROC Analysis}

Fig.~\ref{fig:roc} presents ROC curves for all nine classifiers. The top-6
models cluster tightly near the upper-left corner (AUC~$>0.999$), while DT
(AUC~0.967) and NB (AUC~0.983) are visibly separated, confirming the
superiority of probabilistic and kernel-based methods over simple baselines.
The precision-recall curves corroborate these findings, with LR achieving
average precision~$= 0.999$.

\begin{figure}[!t]
    \centering
    \includegraphics[width=\columnwidth]{28_roc_curves.png}
    \caption{ROC curves (10-fold CV) for all nine classifiers. Top-6 models
    achieve AUC~$>0.999$; Decision Tree (0.967) and Na\"ive Bayes (0.983)
    are clearly separated, confirming ensemble model superiority.}
    \label{fig:roc}
\end{figure}

\subsection{Confusion Matrix Analysis}

Fig.~\ref{fig:confusion} presents confusion matrices for all nine
classifiers on pooled 10-fold CV predictions. Random Forest achieves
zero false negatives (FN~$= 0$), ensuring no CKD patient is missed ---
paramount for clinical screening. Logistic Regression and SVM achieve
zero false positives (FP~$= 0$), indicating perfect specificity.

\begin{figure}[!t]
    \centering
    \includegraphics[width=\columnwidth]{30_confusion_matrices.png}
    \caption{Confusion matrices (pooled 10-fold CV predictions) for all nine
    models. RF achieves FN$=$0 (perfect recall); LR and SVM achieve FP$=$0
    (perfect specificity). Tree-based ensembles show near-zero error rates.}
    \label{fig:confusion}
\end{figure}

The 9-model majority-vote ensemble achieves Accuracy~$= 99.25\%$,
$F_1{=}0.994$, and MCC~$= 0.984$ --- combining individual model strengths.

% ═══════════════════════════════════════════════════════════════════════════
%  V. EXPLAINABILITY AND CLINICAL VALIDATION
% ═══════════════════════════════════════════════════════════════════════════
\section{Explainability and Clinical Validation}

\subsection{SHAP Global Explainability}

SHAP~\cite{lundberg2017} decomposes each prediction into additive feature
contributions via game-theoretic Shapley values. Fig.~\ref{fig:shap}
presents beeswarm plots for the top-4 models, demonstrating consistent
global importance patterns across architectures.

\begin{figure}[!t]
    \centering
    \includegraphics[width=\columnwidth]{41_shap_beeswarm_grid.png}
    \caption{SHAP beeswarm plots for RF, XGBoost, CatBoost, and Gradient
    Boosting. Albumin, serum creatinine, haemoglobin, and specific gravity
    are the dominant features across all four model architectures.}
    \label{fig:shap}
\end{figure}

Table~\ref{tab:shap} maps top SHAP biomarkers to clinical interpretations
per KDIGO guidelines~\cite{kdigo2024}.

\begin{table}[!t]
\centering
\caption{Top SHAP Features with Clinical Interpretation}
\label{tab:shap}
\setlength{\tabcolsep}{2.5pt}
\begin{tabular}{@{}clccl@{}}
\toprule
\textbf{\#} & \textbf{Feat.} & \textbf{|SHAP|} & \textbf{Dir.}
  & \textbf{Clinical Rationale} \\
\midrule
1 & al   & 0.152 & $\uparrow$CKD & Glomerular damage / proteinuria \\
2 & sc   & 0.088 & $\uparrow$CKD & Waste accumulation (GFR$\downarrow$) \\
3 & hemo & 0.086 & $\downarrow$CKD & Renal anaemia (EPO deficit) \\
4 & sg   & 0.062 & $\downarrow$CKD & Reduced concentrating ability \\
5 & bgr  & 0.045 & $\uparrow$CKD & Diabetic nephropathy \\
6 & pcv  & 0.044 & $\downarrow$CKD & Anaemia marker \\
7 & htn  & 0.035 & $\uparrow$CKD & CKD progression accelerator \\
8 & dm   & 0.027 & $\uparrow$CKD & Leading CKD aetiology globally \\
\bottomrule
\end{tabular}
\end{table}

All top SHAP features align with established nephrology biomarkers:
elevated albumin indicates glomerular dysfunction; elevated serum
creatinine reflects reduced GFR; reduced haemoglobin and PCV indicate
erythropoietin deficiency. This concordance provides a foundation for
clinical trust.

\subsection{KDIGO-Stage Clinical Validation and Decision Curve Analysis}

eGFR is computed via the sex-neutral CKD-EPI 2021 equation~\cite{inker2021}
and KDIGO stages G1--G5 are assigned. The tuned Random Forest maintains
recall~$\geq 0.98$ across stages G2--G5. Stage~G1 (normal eGFR but
CKD-labelled by proteinuria criteria) achieves recall~$= 1.00$,
precision~$= 0.93$.

Fig.~\ref{fig:dca} presents Decision Curve Analysis~\cite{vickers2006}
results. NephroScan demonstrates consistently positive net benefit over
both treat-all and treat-none strategies for threshold probabilities
$t \in [0.10, 0.50]$, confirming clinical utility across the entire
practical decision range.

\begin{figure}[!t]
    \centering
    \includegraphics[width=\columnwidth]{55_decision_curve.png}
    \caption{Decision Curve Analysis (DCA) for the NephroScan ensemble and
    individual models. Positive net benefit is maintained over treat-all and
    treat-none baselines for threshold probabilities $t \in [0.10, 0.50]$.}
    \label{fig:dca}
\end{figure}

Subgroup analysis across age ($<\!40$, 40--60, $>\!60$~yr), hypertension,
and diabetes confirms AUC~$\geq 0.98$ in all strata, demonstrating
cross-demographic robustness. Under Specificity~$\geq 0.85$ constraint,
RF achieves Sensitivity~$= 1.000$.

% ═══════════════════════════════════════════════════════════════════════════
%  VI. COMPARISON WITH STATE OF THE ART
% ═══════════════════════════════════════════════════════════════════════════
\section{Comparison with State of the Art}

Table~\ref{tab:sota} benchmarks NephroScan against seven representative
published methods on the UCI CKD dataset.

\begin{table*}[!tp]
\centering
\caption{Comparison with State-of-the-Art Methods on UCI CKD Dataset}
\label{tab:sota}
\setlength{\tabcolsep}{4pt}
\begin{tabular}{@{}llccccccc@{}}
\toprule
\textbf{Author(s)} & \textbf{Method} & \textbf{Year} & \textbf{Acc.}
  & \textbf{AUC} & \textbf{$F_1$} & \textbf{MCC}
  & \textbf{Leak-Free} & \textbf{XAI} \\
\midrule
Aljaaf \textit{et al.}~\cite{aljaaf2019}
  & RF (10-fold CV)       & 2019 & 0.9917 & 0.9970 & 0.9930 & ---  & ?   & No \\
Qin \textit{et al.}~\cite{qin2020}
  & XGBoost + SMOTE       & 2020 & 0.9880 & 0.9930 & 0.9890 & ---  & ?   & No \\
Ogunleye \& Wang~\cite{ogunleye2020}
  & XGBoost + Feat.\ Sel. & 2020 & 0.9933 & 0.9986 & 0.9940 & ---  & ?   & No \\
Islam \textit{et al.}~\cite{islam2022}
  & Ensemble RF+XGB+LR    & 2022 & 0.9950 & 0.9994 & 0.9957 & ---  & ?   & No \\
Ali \textit{et al.}~\cite{ali2023}
  & GB + SHAP             & 2023 & 0.9942 & 0.9988 & 0.9948 & ---  & ?   & Yes \\
Almansour \textit{et al.}~\cite{almansour2023}
  & NN + KNN Imputation   & 2023 & 0.9950 & 0.9990 & 0.9958 & ---  & ?   & No \\
Zhu \textit{et al.}~\cite{zhu2023}
  & CNN + Attention       & 2023 & 0.9930 & 0.9991 & 0.9942 & ---  & ?   & Partial \\
\midrule
\textbf{NephroScan (Ours)}
  & \textbf{9-Model Ens.+SHAP+KDIGO} & \textbf{2026}
  & 0.9925 & \textbf{0.9997} & 0.9940 & \textbf{0.984}
  & \textbf{Yes} & \textbf{Full} \\
\bottomrule
\multicolumn{9}{l}{\footnotesize `?' = leakage-free pipeline not explicitly documented in the original publication.}
\end{tabular}
\end{table*}

NephroScan achieves the \textbf{highest reported AUC} (0.9997). While
accuracy (99.25\%) is marginally below~\cite{islam2022,almansour2023}
(99.50\%), those results lack verified leakage-free pipelines.
NephroScan uniquely provides: (i)~confirmed pipeline leakage prevention,
(ii)~MCC reporting for imbalanced assessment, (iii)~KDIGO-stage clinical
validation, and (iv)~comprehensive cross-model SHAP explainability.

% ═══════════════════════════════════════════════════════════════════════════
%  VII. CONCLUSION
% ═══════════════════════════════════════════════════════════════════════════
\section{Conclusion}

This paper presented NephroScan, an end-to-end explainable machine learning
framework for CKD detection. Through a rigorous seven-phase pipeline ---
encompassing leakage-free preprocessing, four-method consensus feature
selection, Bayesian hyperparameter optimisation, and SHAP-based clinical
explainability --- we demonstrated:

\begin{itemize}
    \item Leakage-free 10-fold CV achieves AUC~$= 0.9997$ (Logistic
    Regression) and $F_1{=}0.994$ (9-model ensemble).
    \item A compact 7-feature consensus subset retains $>99.9\%$ AUC,
    enabling minimal-feature clinical assessment.
    \item SHAP analysis confirms albumin, serum creatinine, haemoglobin,
    and specific gravity as dominant biomarkers, consistent with KDIGO
    guidelines.
    \item Random Forest achieves zero false negatives across all CV folds,
    critical for clinical screening applications.
    \item Clinical validation against KDIGO staging and decision-curve
    analysis confirms real-world applicability.
\end{itemize}

\textbf{Limitations:} The study uses a single dataset ($n{=}400$); external
validation on independent cohorts (NHANES, hospital EHR) is required.
The dataset lacks sex variable, necessitating sex-neutral CKD-EPI
approximation. No longitudinal data precludes progression modelling.

\textbf{Future Work:} Multi-class G1--G5 CKD staging classification,
external cohort validation (NHANES, hospital EHR), federated learning
for privacy-preserving multi-site deployment, and full integration of
the Flask-based clinical decision support system with hospital
information systems.

% ═══════════════════════════════════════════════════════════════════════════
\section*{Acknowledgement}
The authors thank Apollo Hospitals, India, for making the CKD dataset
available via the UCI Machine Learning Repository.

% ═══════════════════════════════════════════════════════════════════════════
%  REFERENCES
% ═══════════════════════════════════════════════════════════════════════════
\begin{thebibliography}{99}

\bibitem{kdigo2024}
Kidney Disease: Improving Global Outcomes (KDIGO) CKD Work Group,
``KDIGO 2024 clinical practice guideline for the evaluation and management
of chronic kidney disease,'' \textit{Kidney Int.}, vol.~105, no.~4
(Suppl.), pp.~S117--S314, Apr.\ 2024.

\bibitem{bikbov2020}
B.~Bikbov \textit{et al.} (GBD CKD Collaboration), ``Global, regional, and
national burden of chronic kidney disease, 1990--2017,'' \textit{Lancet},
vol.~395, no.~10225, pp.~709--733, Feb.\ 2020.

\bibitem{inker2021}
L.~A. Inker \textit{et al.}, ``New creatinine- and cystatin C--based
equations to estimate GFR without race,'' \textit{New Engl. J. Med.},
vol.~385, no.~19, pp.~1737--1749, Nov.\ 2021.

\bibitem{uci2015}
P.~Soundarapandian, ``Chronic Kidney Disease Data Set,'' UCI Machine
Learning Repository, 2015. [Online]. Available:
\url{https://archive.ics.uci.edu/ml/datasets/chronic\_kidney\_disease}

\bibitem{kaufman2012}
S.~Kaufman, S.~Rosset, C.~Perlich, and O.~Stitelman, ``Leakage in data
mining: Formulation, detection, and avoidance,'' \textit{ACM Trans. Knowl.
Discov. Data}, vol.~6, no.~4, Art.~no.\ 15, Dec.\ 2012.

\bibitem{scikit2011}
F.~Pedregosa \textit{et al.}, ``Scikit-learn: Machine learning in Python,''
\textit{J. Mach. Learn. Res.}, vol.~12, pp.~2825--2830, 2011.

\bibitem{chen2016}
T.~Chen and C.~Guestrin, ``XGBoost: A scalable tree boosting system,'' in
\textit{Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining},
San Francisco, CA, 2016, pp.~785--794.

\bibitem{akiba2019}
T.~Akiba, S.~Sano, T.~Yanase, T.~Ohta, and M.~Koyama, ``Optuna: A
next-generation hyperparameter optimization framework,'' in \textit{Proc.
25th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining}, Anchorage, AK,
2019, pp.~2623--2631.

\bibitem{lundberg2017}
S.~M. Lundberg and S.-I. Lee, ``A unified approach to interpreting model
predictions,'' in \textit{Adv. Neural Inf. Process. Syst. (NeurIPS)},
vol.~30, 2017, pp.~4765--4774.

\bibitem{vickers2006}
A.~J. Vickers and E.~B. Elkin, ``Decision curve analysis: A novel method
for evaluating prediction models,'' \textit{Med. Decis. Making}, vol.~26,
no.~6, pp.~565--574, Nov.\ 2006.

\bibitem{chicco2020}
D.~Chicco and G.~Jurman, ``The advantages of the Matthews correlation
coefficient (MCC) over $F_1$ score and accuracy in binary classification
evaluation,'' \textit{BMC Genomics}, vol.~21, no.~1, Art.~no.\ 6, Jan.\ 2020.

\bibitem{aljaaf2019}
A.~J. Aljaaf \textit{et al.}, ``Early prediction of chronic kidney disease
using machine learning supported by predictive analytics,'' in \textit{Proc.
IEEE Int. Symp. Comput.-Based Med. Syst. (CBMS)}, Cordoba, Spain, Jun.\ 2019,
pp.~1--6.

\bibitem{qin2020}
X.~Qin \textit{et al.}, ``Research on the detection of chronic kidney
disease based on machine learning,'' \textit{IEEE Access}, vol.~8,
pp.~178096--178107, Sep.\ 2020.

\bibitem{ogunleye2020}
A.~Ogunleye and Q.-G. Wang, ``XGBoost model for chronic kidney disease
diagnosis,'' \textit{IEEE/ACM Trans. Comput. Biol. Bioinf.}, vol.~17, no.~6,
pp.~2131--2140, Nov./Dec.\ 2020.

\bibitem{islam2022}
M.~S. Islam \textit{et al.}, ``An ensemble learning system for chronic
kidney disease classification,'' \textit{Healthcare}, vol.~10, no.~7,
Art.~no.\ 1191, Jun.\ 2022.

\bibitem{almansour2023}
N.~A. Almansour \textit{et al.}, ``Neural network and AdaBoost algorithm
for classification of chronic kidney disease,'' \textit{Comput. Biol. Med.},
vol.~158, Art.~no.\ 106817, May 2023.

\bibitem{ali2023}
M.~M. Ali \textit{et al.}, ``Explainable machine learning for CKD risk
stratification using SHAP-based gradient boosting,'' \textit{IEEE J. Biomed.
Health Inform.}, vol.~27, no.~8, pp.~3947--3958, Aug.\ 2023.

\bibitem{zhu2023}
Y.~Zhu \textit{et al.}, ``Attention-based convolutional neural network for
chronic kidney disease detection from clinical tabular data,'' \textit{Artif.
Intell. Med.}, vol.~139, Art.~no.\ 102543, May 2023.

\end{thebibliography}

\balance
\end{document}
